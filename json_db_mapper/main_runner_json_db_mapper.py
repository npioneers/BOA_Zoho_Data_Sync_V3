#!/usr/bin/env python3
"""
Main Runner for JSON DB Mapper
Background runner that takes various options and runs the required functionality
"""
import sys
import os
import argparse
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any

# Add the core module to path
sys.path.append(str(Path(__file__).parent / "core"))

try:
    # Import available modules and provide fallbacks for missing ones
    import sqlite3
    from pathlib import Path
    
    # Try to import core modules, provide stubs if they don't exist
    try:
        from core.runner import Runner
    except ImportError:
        class Runner:
            def analyze_database(self, db_path):
                return {"tables": [], "message": "Stub implementation"}
            def create_mapping_tables(self, db_path):
                return {"message": "Stub implementation"}
    
    try:
        from core.field_mapper import FieldMapper
    except ImportError:
        class FieldMapper:
            def run_mapping(self, db_path):
                return {"message": "Stub implementation"}
    
    try:
        from core.table_structure_analyzer import TableStructureAnalyzer
    except ImportError:
        class TableStructureAnalyzer:
            def analyze(self, db_path):
                return {"message": "Stub implementation"}
    
    # Try to import other modules with fallbacks
    try:
        from add_field_columns import validate_and_fix_schema
    except ImportError:
        def validate_and_fix_schema(db_path):
            return {"message": "validate_and_fix_schema not available"}
    
    try:
        from run_field_mapping import run_field_level_mapping
    except ImportError:
        def run_field_level_mapping(db_path):
            return {"message": "run_field_level_mapping not available"}
    
    try:
        from view_creation.create_final_views import create_final_views
    except ImportError:
        def create_final_views():
            return {"message": "create_final_views not available"}
    
    try:
        from view_creation.create_all_final_views import create_all_final_views
    except ImportError:
        def create_all_final_views():
            return {"message": "create_all_final_views not available"}
    
    try:
        from manual_ai_analysis.comprehensive_mapping_analyzer import ComprehensiveMappingAnalyzer
    except ImportError:
        class ComprehensiveMappingAnalyzer:
            def run_analysis(self):
                return {"message": "ComprehensiveMappingAnalyzer not available"}
    
    try:
        from manual_ai_analysis.critical_issues_analyzer import CriticalIssuesAnalyzer
    except ImportError:
        class CriticalIssuesAnalyzer:
            def analyze_critical_issues(self):
                return {"message": "CriticalIssuesAnalyzer not available"}

except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("Using fallback implementations for missing modules")
    # Will use stub implementations

class JsonDbMapperRunner:
    """Main background runner for JSON DB Mapper operations"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize the runner with configuration"""
        self.config = config or {}
        self.setup_logging()
        
        # Default database paths
        self.default_production_db = "data/database/production.db"
        self.default_json_db = "data/database/json_sync.db"
        
    def setup_logging(self):
        """Setup logging configuration"""
        log_level = self.config.get('log_level', 'INFO')
        logging.basicConfig(
            level=getattr(logging, log_level),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('json_db_mapper_runner.log')
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def analyze_tables(self, db_path: str) -> Dict[str, Any]:
        """Analyze database tables structure"""
        self.logger.info(f"Analyzing tables in: {db_path}")
        
        try:
            runner = Runner()
            result = runner.analyze_database(db_path)
            
            self.logger.info(f"Table analysis completed: {len(result.get('tables', []))} tables found")
            return result
            
        except Exception as e:
            self.logger.error(f"Table analysis failed: {e}")
            return {"error": str(e)}
    
    def create_mapping_tables(self, db_path: str) -> Dict[str, Any]:
        """Create mapping tables in the database"""
        self.logger.info(f"üó∫Ô∏è Creating mapping tables in: {db_path}")
        
        try:
            runner = Runner()
            result = runner.create_mapping_tables(db_path)
            
            self.logger.info(f"‚úÖ Mapping tables created successfully")
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Mapping table creation failed: {e}")
            return {"error": str(e)}
    
    def update_schema(self, db_path: str) -> Dict[str, Any]:
        """Update database schema with field columns"""
        self.logger.info(f"üîß Updating schema in: {db_path}")
        
        try:
            result = validate_and_fix_schema(db_path)
            
            self.logger.info(f"‚úÖ Schema update completed")
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Schema update failed: {e}")
            return {"error": str(e)}
    
    def run_field_mapping(self, db_path: str) -> Dict[str, Any]:
        """Run field-level mapping analysis"""
        self.logger.info(f"üó∫Ô∏è Running field mapping in: {db_path}")
        
        try:
            result = run_field_level_mapping(db_path)
            
            self.logger.info(f"‚úÖ Field mapping completed")
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Field mapping failed: {e}")
            return {"error": str(e)}
    
    def create_views(self, view_type: str = "final") -> Dict[str, Any]:
        """Create database views"""
        self.logger.info(f"üìä Creating {view_type} views")
        
        try:
            if view_type == "final":
                result = create_final_views()
            elif view_type == "all_final":
                result = create_all_final_views()
            else:
                raise ValueError(f"Unknown view type: {view_type}")
            
            self.logger.info(f"‚úÖ View creation completed")
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå View creation failed: {e}")
            return {"error": str(e)}
    
    def run_comprehensive_analysis(self, db_path: str) -> Dict[str, Any]:
        """Run comprehensive mapping analysis"""
        self.logger.info(f"üìä Running comprehensive analysis in: {db_path}")
        
        try:
            analyzer = ComprehensiveMappingAnalyzer()
            result = analyzer.run_analysis()
            
            self.logger.info(f"‚úÖ Comprehensive analysis completed")
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Comprehensive analysis failed: {e}")
            return {"error": str(e)}
    
    def run_critical_issues_analysis(self, db_path: str) -> Dict[str, Any]:
        """Run critical issues analysis"""
        self.logger.info(f"‚ö†Ô∏è Running critical issues analysis in: {db_path}")
        
        try:
            analyzer = CriticalIssuesAnalyzer()
            result = analyzer.analyze_critical_issues()
            
            self.logger.info(f"‚úÖ Critical issues analysis completed")
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Critical issues analysis failed: {e}")
            return {"error": str(e)}
    
    def run_full_pipeline(self, production_db: str = None, json_db: str = None) -> Dict[str, Any]:
        """Run the complete JSON DB Mapper pipeline"""
        production_db = production_db or self.default_production_db
        json_db = json_db or self.default_json_db
        
        self.logger.info(f"üöÄ Running full JSON DB Mapper pipeline")
        self.logger.info(f"   Production DB: {production_db}")
        self.logger.info(f"   JSON DB: {json_db}")
        
        results = {}
        
        try:
            # Step 1: Analyze tables
            self.logger.info("üìã Step 1: Analyzing tables")
            results['analyze_production'] = self.analyze_tables(production_db)
            if json_db != production_db:
                results['analyze_json'] = self.analyze_tables(json_db)
            
            # Step 2: Create mapping tables
            self.logger.info("üìã Step 2: Creating mapping tables")
            results['create_mappings'] = self.create_mapping_tables(production_db)
            
            # Step 3: Update schema
            self.logger.info("üìã Step 3: Updating schema")
            results['update_schema'] = self.update_schema(production_db)
            
            # Step 4: Run field mapping
            self.logger.info("üìã Step 4: Running field mapping")
            results['field_mapping'] = self.run_field_mapping(production_db)
            
            # Step 5: Create views
            self.logger.info("üìã Step 5: Creating final views")
            results['create_views'] = self.create_views("all_final")
            
            # Step 6: Run analysis
            self.logger.info("üìã Step 6: Running comprehensive analysis")
            results['comprehensive_analysis'] = self.run_comprehensive_analysis(production_db)
            
            self.logger.info("‚úÖ Full pipeline completed successfully")
            results['status'] = 'success'
            
        except Exception as e:
            self.logger.error(f"‚ùå Full pipeline failed: {e}")
            results['status'] = 'failed'
            results['error'] = str(e)
        
        return results

def main():
    """Main entry point for the runner"""
    parser = argparse.ArgumentParser(description="JSON DB Mapper Background Runner")
    
    # Database paths
    parser.add_argument("--production-db", default="data/database/production.db",
                       help="Path to production database")
    parser.add_argument("--json-db", default="data/database/json_sync.db",
                       help="Path to JSON database")
    
    # Operations
    parser.add_argument("--operation", choices=[
        'analyze', 'create-mappings', 'update-schema', 'field-mapping',
        'create-views', 'comprehensive-analysis', 'critical-analysis', 'full-pipeline'
    ], required=True, help="Operation to perform")
    
    # View options
    parser.add_argument("--view-type", choices=['final', 'all_final'], default='final',
                       help="Type of views to create")
    
    # General options
    parser.add_argument("--log-level", choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                       default='INFO', help="Logging level")
    parser.add_argument("--dry-run", action='store_true',
                       help="Show what would be done without executing")
    
    args = parser.parse_args()
    
    # Initialize runner
    config = {
        'log_level': args.log_level,
        'dry_run': args.dry_run
    }
    
    runner = JsonDbMapperRunner(config)
    
    # Execute operation
    result = None
    
    if args.operation == 'analyze':
        result = runner.analyze_tables(args.production_db)
    elif args.operation == 'create-mappings':
        result = runner.create_mapping_tables(args.production_db)
    elif args.operation == 'update-schema':
        result = runner.update_schema(args.production_db)
    elif args.operation == 'field-mapping':
        result = runner.run_field_mapping(args.production_db)
    elif args.operation == 'create-views':
        result = runner.create_views(args.view_type)
    elif args.operation == 'comprehensive-analysis':
        result = runner.run_comprehensive_analysis(args.production_db)
    elif args.operation == 'critical-analysis':
        result = runner.run_critical_issues_analysis(args.production_db)
    elif args.operation == 'full-pipeline':
        result = runner.run_full_pipeline(args.production_db, args.json_db)
    
    # Output result
    if result:
        if result.get('error'):
            print(f"‚ùå Operation failed: {result['error']}")
            sys.exit(1)
        else:
            print(f"‚úÖ Operation completed successfully")
            if args.log_level == 'DEBUG':
                print(f"Result: {result}")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
