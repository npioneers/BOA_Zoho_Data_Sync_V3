{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d63007",
   "metadata": {},
   "source": [
    "# CSV Field Analysis and Mappings Update\n",
    "## Date: 2025-07-05\n",
    "\n",
    "This notebook analyzes CSV files to identify additional fields that are not currently mapped in mappings.py.\n",
    "These are likely custom fields not documented in the Zoho API.\n",
    "\n",
    "### Objectives:\n",
    "1. Load all CSV files and examine their column structures\n",
    "2. Compare CSV columns with existing mappings\n",
    "3. Identify missing/unmapped fields\n",
    "4. Update mappings.py to include all CSV fields\n",
    "5. Maintain field names as they appear in CSV (custom fields)\n",
    "\n",
    "### Process:\n",
    "- ‚úÖ Backup created: `mappings_backup_2025-07-05_16-37-59.py`\n",
    "- üîÑ Analyzing CSV field structures\n",
    "- üîÑ Identifying unmapped fields  \n",
    "- üîÑ Updating mappings.py with new fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be47561c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Working directory: c:\\Users\\User\\Documents\\Projects\\Automated_Operations\\Zoho_Data_Sync\\notebooks\n",
      "Data directory: c:\\Users\\User\\Documents\\Projects\\Automated_Operations\\Zoho_Data_Sync\\data\\csv\\Nangsel Pioneers_2025-06-22\n",
      "Data directory exists: True\n",
      "Mappings file: c:\\Users\\User\\Documents\\Projects\\Automated_Operations\\Zoho_Data_Sync\\src\\data_pipeline\\mappings.py\n"
     ]
    }
   ],
   "source": [
    "# Section 1: Setup and Imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Any\n",
    "import re\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = Path.cwd().parent / 'data' / 'csv' / 'Nangsel Pioneers_2025-06-22'\n",
    "SRC_DIR = Path.cwd().parent / 'src'\n",
    "MAPPINGS_FILE = SRC_DIR / 'data_pipeline' / 'mappings.py'\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Data directory exists: {DATA_DIR.exists()}\")\n",
    "print(f\"Mappings file: {MAPPINGS_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "567f14f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current mappings loaded successfully!\n",
      "Total entities in schema: 10\n",
      "Entity mappings configured:\n",
      "  Invoices: 37 mapped fields\n",
      "  Items: 24 mapped fields\n",
      "  Contacts: 23 mapped fields\n",
      "  Bills: 35 mapped fields\n",
      "  CustomerPayments: 20 mapped fields\n",
      "  VendorPayments: 20 mapped fields\n",
      "  SalesOrders: 32 mapped fields\n",
      "  PurchaseOrders: 32 mapped fields\n",
      "  CreditNotes: 31 mapped fields\n"
     ]
    }
   ],
   "source": [
    "# Section 2: Load Current Mappings\n",
    "from data_pipeline.mappings import (\n",
    "    CANONICAL_SCHEMA,\n",
    "    INVOICE_CSV_MAP,\n",
    "    ITEMS_CSV_MAP,\n",
    "    CONTACTS_CSV_MAP,\n",
    "    BILLS_CSV_MAP,\n",
    "    CUSTOMER_PAYMENTS_CSV_MAP,\n",
    "    VENDOR_PAYMENTS_CSV_MAP,\n",
    "    SALES_ORDERS_CSV_MAP,\n",
    "    PURCHASE_ORDERS_CSV_MAP,\n",
    "    CREDIT_NOTES_CSV_MAP,\n",
    "    get_entity_csv_mapping\n",
    ")\n",
    "\n",
    "print(\"Current mappings loaded successfully!\")\n",
    "print(f\"Total entities in schema: {len(CANONICAL_SCHEMA)}\")\n",
    "\n",
    "# Map entity names to their CSV mappings\n",
    "ENTITY_MAPPINGS = {\n",
    "    'Invoices': INVOICE_CSV_MAP,\n",
    "    'Items': ITEMS_CSV_MAP,\n",
    "    'Contacts': CONTACTS_CSV_MAP,\n",
    "    'Bills': BILLS_CSV_MAP,\n",
    "    'CustomerPayments': CUSTOMER_PAYMENTS_CSV_MAP,\n",
    "    'VendorPayments': VENDOR_PAYMENTS_CSV_MAP,\n",
    "    'SalesOrders': SALES_ORDERS_CSV_MAP,\n",
    "    'PurchaseOrders': PURCHASE_ORDERS_CSV_MAP,\n",
    "    'CreditNotes': CREDIT_NOTES_CSV_MAP\n",
    "}\n",
    "\n",
    "print(\"Entity mappings configured:\")\n",
    "for entity, mapping in ENTITY_MAPPINGS.items():\n",
    "    print(f\"  {entity}: {len(mapping)} mapped fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad0eac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 CSV files:\n",
      "  ‚ö†Ô∏è  Activity Logs.csv -> No mapping found\n",
      "  ‚úÖ Bill.csv -> Bills\n",
      "  ‚ö†Ô∏è  Bill_Of_Entry.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Budget.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Chart_of_Accounts.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  CN_Verification.csv -> No mapping found\n",
      "  ‚úÖ Contacts.csv -> Contacts\n",
      "  ‚ö†Ô∏è  Contact_Persons.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Cost_Tracking.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Creditnotes_Invoice.csv -> No mapping found\n",
      "  ‚úÖ Credit_Note.csv -> CreditNotes\n",
      "  ‚úÖ Customer_Payment.csv -> CustomerPayments\n",
      "  ‚ö†Ô∏è  Deposit.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Direct_Dealer_Supply_Exp.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Exchange_Rate.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Expense.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Fixed_Asset.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Important_Update_Records.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Inventory_Adjustment.csv -> No mapping found\n",
      "  ‚úÖ Invoice.csv -> Invoices\n",
      "  ‚úÖ Item.csv -> Items\n",
      "  ‚ö†Ô∏è  Journal.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Plumber_.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Plumber_Transaction.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Price_lists.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Project.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Projects.csv -> No mapping found\n",
      "  ‚úÖ Purchase_Order.csv -> PurchaseOrders\n",
      "  ‚ö†Ô∏è  Purchase_Price_lists.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Quote.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Recurring_Bill.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Recurring_Expense.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Recurring_Invoice.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Refund.csv -> No mapping found\n",
      "  ‚úÖ Sales_Order.csv -> SalesOrders\n",
      "  ‚ö†Ô∏è  Special_Sch_&_Tgt.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Task.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Tasks.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Timesheet.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Transfer_Fund.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Vehicle_Rep-Maint_Record.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Vendors.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Vendor_Contact_Persons.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Vendor_Credits.csv -> No mapping found\n",
      "  ‚ö†Ô∏è  Vendor_Credits_Refund.csv -> No mapping found\n",
      "  ‚úÖ Vendor_Payment.csv -> VendorPayments\n",
      "\n",
      "Mapped 9 CSV files to entities\n"
     ]
    }
   ],
   "source": [
    "# Section 3: Discover CSV Files and Map to Entities\n",
    "if DATA_DIR.exists():\n",
    "    csv_files = list(DATA_DIR.glob('*.csv'))\n",
    "    print(f\"Found {len(csv_files)} CSV files:\")\n",
    "    \n",
    "    # Map CSV files to entity names\n",
    "    csv_to_entity_map = {\n",
    "        'Invoice.csv': 'Invoices',\n",
    "        'Item.csv': 'Items', \n",
    "        'Contacts.csv': 'Contacts',\n",
    "        'Bill.csv': 'Bills',\n",
    "        'Customer_Payment.csv': 'CustomerPayments',\n",
    "        'Vendor_Payment.csv': 'VendorPayments',\n",
    "        'Sales_Order.csv': 'SalesOrders',\n",
    "        'Purchase_Order.csv': 'PurchaseOrders',\n",
    "        'Credit_Note.csv': 'CreditNotes'\n",
    "    }\n",
    "    \n",
    "    available_files = {}\n",
    "    for csv_file in csv_files:\n",
    "        file_name = csv_file.name\n",
    "        entity = csv_to_entity_map.get(file_name)\n",
    "        if entity:\n",
    "            available_files[entity] = csv_file\n",
    "            print(f\"  ‚úÖ {file_name} -> {entity}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  {file_name} -> No mapping found\")\n",
    "    \n",
    "    print(f\"\\nMapped {len(available_files)} CSV files to entities\")\n",
    "else:\n",
    "    print(f\"‚ùå Data directory not found: {DATA_DIR}\")\n",
    "    available_files = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d866cd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALYZING CSV COLUMN STRUCTURES ===\n",
      "\n",
      "--- Analyzing Bills (Bill.csv) ---\n",
      "  Total CSV columns: 64\n",
      "  Currently mapped: 35\n",
      "  Unmapped columns: 44\n",
      "  üîç Unmapped fields found:\n",
      "    - Account\n",
      "    - Account Code\n",
      "    - Accounts Payable\n",
      "    - Adjustment\n",
      "    - Adjustment Account\n",
      "    - Adjustment Description\n",
      "    - Approved By\n",
      "    - Approved Date\n",
      "    - Bill Status\n",
      "    - Bill Type\n",
      "    ... and 34 more\n",
      "  ‚ö†Ô∏è  Mapped but not in CSV: 15\n",
      "    - Account ID\n",
      "    - Account Name\n",
      "    - Created Time\n",
      "    - Item Description\n",
      "    - Item ID\n",
      "\n",
      "--- Analyzing Contacts (Contacts.csv) ---\n",
      "  Total CSV columns: 72\n",
      "  Currently mapped: 23\n",
      "  Unmapped columns: 53\n",
      "  üîç Unmapped fields found:\n",
      "    - Accounts Receivable\n",
      "    - Bank Account Payment\n",
      "    - Billing Attention\n",
      "    - Billing City\n",
      "    - Billing Code\n",
      "    - Billing Country\n",
      "    - Billing County\n",
      "    - Billing Fax\n",
      "    - Billing Phone\n",
      "    - Billing State\n",
      "    ... and 43 more\n",
      "  ‚ö†Ô∏è  Mapped but not in CSV: 4\n",
      "    - Contact Person ID\n",
      "    - Email\n",
      "    - Mobile\n",
      "    - Vendor Display Name\n",
      "\n",
      "--- Analyzing CreditNotes (Credit_Note.csv) ---\n",
      "  Total CSV columns: 87\n",
      "  Currently mapped: 31\n",
      "  Unmapped columns: 74\n",
      "  üîç Unmapped fields found:\n",
      "    - Account\n",
      "    - Account Code\n",
      "    - Accounts Receivable\n",
      "    - Adjustment\n",
      "    - Adjustment Account\n",
      "    - Adjustment Description\n",
      "    - Applied Invoice Number\n",
      "    - Billing Address\n",
      "    - Billing Attention\n",
      "    - Billing City\n",
      "    ... and 64 more\n",
      "  ‚ö†Ô∏è  Mapped but not in CSV: 18\n",
      "    - Created Time\n",
      "    - Credit Note ID\n",
      "    - Date\n",
      "    - Item Description\n",
      "    - Item ID\n",
      "\n",
      "--- Analyzing CustomerPayments (Customer_Payment.csv) ---\n",
      "  Total CSV columns: 29\n",
      "  Currently mapped: 20\n",
      "  Unmapped columns: 18\n",
      "  üîç Unmapped fields found:\n",
      "    - Amount Applied to Invoice\n",
      "    - Branch ID\n",
      "    - Branch Name\n",
      "    - CustomerID\n",
      "    - CustomerPayment ID\n",
      "    - Deposit To\n",
      "    - Deposit To Account Code\n",
      "    - Early Payment Discount\n",
      "    - Invoice Date\n",
      "    - Invoice Payment Applied Date\n",
      "    ... and 8 more\n",
      "  ‚ö†Ô∏è  Mapped but not in CSV: 9\n",
      "    - Amount Applied\n",
      "    - Application ID\n",
      "    - Customer ID\n",
      "    - Invoice ID\n",
      "    - Last Modified Time\n",
      "\n",
      "--- Analyzing Invoices (Invoice.csv) ---\n",
      "  Total CSV columns: 122\n",
      "  Currently mapped: 37\n",
      "  Unmapped columns: 100\n",
      "  üîç Unmapped fields found:\n",
      "    - 2Checkout\n",
      "    - Account\n",
      "    - Account Code\n",
      "    - Accounts Receivable\n",
      "    - Adjustment\n",
      "    - Adjustment Account\n",
      "    - Adjustment Description\n",
      "    - Authorize.Net\n",
      "    - Billing Attention\n",
      "    - Billing City\n",
      "    ... and 90 more\n",
      "  ‚ö†Ô∏è  Mapped but not in CSV: 15\n",
      "    - Created Time\n",
      "    - Item Description\n",
      "    - Item ID\n",
      "    - Last Modified Time\n",
      "    - Line Item ID\n",
      "\n",
      "--- Analyzing Items (Item.csv) ---\n",
      "  Total CSV columns: 41\n",
      "  Currently mapped: 24\n",
      "  Unmapped columns: 29\n",
      "  üîç Unmapped fields found:\n",
      "    - Account\n",
      "    - Account Code\n",
      "    - CF.Item Location\n",
      "    - CF.M Box\n",
      "    - CF.Manufacturer\n",
      "    - CF.Product Category\n",
      "    - CF.Product Sale Category\n",
      "    - CF.S Box Qty\n",
      "    - CF.SKU category\n",
      "    - Inventory Account\n",
      "    ... and 19 more\n",
      "  ‚ö†Ô∏è  Mapped but not in CSV: 12\n",
      "    - Account ID\n",
      "    - Account Name\n",
      "    - Category\n",
      "    - Created Time\n",
      "    - Inventory Account ID\n",
      "\n",
      "--- Analyzing PurchaseOrders (Purchase_Order.csv) ---\n",
      "  Total CSV columns: 75\n",
      "  Currently mapped: 32\n",
      "  Unmapped columns: 64\n",
      "  üîç Unmapped fields found:\n",
      "    - Account\n",
      "    - Account Code\n",
      "    - Address\n",
      "    - Adjustment\n",
      "    - Adjustment Description\n",
      "    - Approved By\n",
      "    - Approved Date\n",
      "    - Attention\n",
      "    - Branch ID\n",
      "    - Branch Name\n",
      "    ... and 54 more\n",
      "  ‚ö†Ô∏è  Mapped but not in CSV: 21\n",
      "    - Billing Address\n",
      "    - Created Time\n",
      "    - Date\n",
      "    - Delivery Address\n",
      "    - Expected Delivery Date\n",
      "\n",
      "--- Analyzing SalesOrders (Sales_Order.csv) ---\n",
      "  Total CSV columns: 83\n",
      "  Currently mapped: 32\n",
      "  Unmapped columns: 68\n",
      "  üîç Unmapped fields found:\n",
      "    - Account\n",
      "    - Account Code\n",
      "    - Adjustment\n",
      "    - Adjustment Description\n",
      "    - Billing City\n",
      "    - Billing Code\n",
      "    - Billing Country\n",
      "    - Billing Fax\n",
      "    - Billing Phone\n",
      "    - Billing State\n",
      "    ... and 58 more\n",
      "  ‚ö†Ô∏è  Mapped but not in CSV: 17\n",
      "    - Created Time\n",
      "    - Date\n",
      "    - Item Description\n",
      "    - Item ID\n",
      "    - Last Modified Time\n",
      "\n",
      "--- Analyzing VendorPayments (Vendor_Payment.csv) ---\n",
      "  Total CSV columns: 28\n",
      "  Currently mapped: 20\n",
      "  Unmapped columns: 19\n",
      "  üîç Unmapped fields found:\n",
      "    - Bank Reference Number\n",
      "    - Bill Amount\n",
      "    - Bill Date\n",
      "    - Bill Payment Applied Date\n",
      "    - Branch ID\n",
      "    - Branch Name\n",
      "    - EmailID\n",
      "    - Mode\n",
      "    - PIPayment ID\n",
      "    - Paid Through\n",
      "    ... and 9 more\n",
      "  ‚ö†Ô∏è  Mapped but not in CSV: 11\n",
      "    - Amount Applied\n",
      "    - Application ID\n",
      "    - Bank Charges\n",
      "    - Bill ID\n",
      "    - Created Time\n",
      "\n",
      "Analysis completed for 9 entities\n"
     ]
    }
   ],
   "source": [
    "# Section 4: Analyze CSV Column Structures\n",
    "csv_analysis = {}\n",
    "\n",
    "print(\"=== ANALYZING CSV COLUMN STRUCTURES ===\")\n",
    "print()\n",
    "\n",
    "for entity, csv_file in available_files.items():\n",
    "    print(f\"--- Analyzing {entity} ({csv_file.name}) ---\")\n",
    "    \n",
    "    try:\n",
    "        # Load CSV to get column names (just first few rows for efficiency)\n",
    "        df = pd.read_csv(csv_file, nrows=5)\n",
    "        csv_columns = list(df.columns)\n",
    "        \n",
    "        # Get current mapping for this entity\n",
    "        current_mapping = ENTITY_MAPPINGS.get(entity, {})\n",
    "        mapped_columns = set(current_mapping.keys())\n",
    "        csv_columns_set = set(csv_columns)\n",
    "        \n",
    "        # Find unmapped columns\n",
    "        unmapped_columns = csv_columns_set - mapped_columns\n",
    "        \n",
    "        # Find mapped columns that don't exist in CSV\n",
    "        missing_in_csv = mapped_columns - csv_columns_set\n",
    "        \n",
    "        csv_analysis[entity] = {\n",
    "            'csv_file': csv_file.name,\n",
    "            'total_csv_columns': len(csv_columns),\n",
    "            'csv_columns': csv_columns,\n",
    "            'currently_mapped': len(mapped_columns),\n",
    "            'mapped_columns': sorted(mapped_columns),\n",
    "            'unmapped_count': len(unmapped_columns),\n",
    "            'unmapped_columns': sorted(unmapped_columns),\n",
    "            'missing_in_csv_count': len(missing_in_csv),\n",
    "            'missing_in_csv': sorted(missing_in_csv)\n",
    "        }\n",
    "        \n",
    "        print(f\"  Total CSV columns: {len(csv_columns)}\")\n",
    "        print(f\"  Currently mapped: {len(mapped_columns)}\")\n",
    "        print(f\"  Unmapped columns: {len(unmapped_columns)}\")\n",
    "        \n",
    "        if unmapped_columns:\n",
    "            print(f\"  üîç Unmapped fields found:\")\n",
    "            for col in sorted(unmapped_columns)[:10]:  # Show first 10\n",
    "                print(f\"    - {col}\")\n",
    "            if len(unmapped_columns) > 10:\n",
    "                print(f\"    ... and {len(unmapped_columns) - 10} more\")\n",
    "        \n",
    "        if missing_in_csv:\n",
    "            print(f\"  ‚ö†Ô∏è  Mapped but not in CSV: {len(missing_in_csv)}\")\n",
    "            for col in sorted(missing_in_csv)[:5]:\n",
    "                print(f\"    - {col}\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error analyzing {csv_file.name}: {e}\")\n",
    "        csv_analysis[entity] = {'error': str(e)}\n",
    "        print()\n",
    "\n",
    "print(f\"Analysis completed for {len(csv_analysis)} entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52ca817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY OF UNMAPPED FIELDS ANALYSIS ===\n",
      "\n",
      "üìã Bills:\n",
      "   Total CSV columns: 64\n",
      "   Currently mapped: 35\n",
      "   Unmapped: 44\n",
      "   Coverage: 54.7%\n",
      "   üîç Sample unmapped fields: Account, Account Code, Accounts Payable...\n",
      "\n",
      "üìã Contacts:\n",
      "   Total CSV columns: 72\n",
      "   Currently mapped: 23\n",
      "   Unmapped: 53\n",
      "   Coverage: 31.9%\n",
      "   üîç Sample unmapped fields: Accounts Receivable, Bank Account Payment, Billing Attention...\n",
      "\n",
      "üìã CreditNotes:\n",
      "   Total CSV columns: 87\n",
      "   Currently mapped: 31\n",
      "   Unmapped: 74\n",
      "   Coverage: 35.6%\n",
      "   üîç Sample unmapped fields: Account, Account Code, Accounts Receivable...\n",
      "\n",
      "üìã CustomerPayments:\n",
      "   Total CSV columns: 29\n",
      "   Currently mapped: 20\n",
      "   Unmapped: 18\n",
      "   Coverage: 69.0%\n",
      "   üîç Sample unmapped fields: Amount Applied to Invoice, Branch ID, Branch Name...\n",
      "\n",
      "üìã Invoices:\n",
      "   Total CSV columns: 122\n",
      "   Currently mapped: 37\n",
      "   Unmapped: 100\n",
      "   Coverage: 30.3%\n",
      "   üîç Sample unmapped fields: 2Checkout, Account, Account Code...\n",
      "\n",
      "üìã Items:\n",
      "   Total CSV columns: 41\n",
      "   Currently mapped: 24\n",
      "   Unmapped: 29\n",
      "   Coverage: 58.5%\n",
      "   üîç Sample unmapped fields: Account, Account Code, CF.Item Location...\n",
      "\n",
      "üìã PurchaseOrders:\n",
      "   Total CSV columns: 75\n",
      "   Currently mapped: 32\n",
      "   Unmapped: 64\n",
      "   Coverage: 42.7%\n",
      "   üîç Sample unmapped fields: Account, Account Code, Address...\n",
      "\n",
      "üìã SalesOrders:\n",
      "   Total CSV columns: 83\n",
      "   Currently mapped: 32\n",
      "   Unmapped: 68\n",
      "   Coverage: 38.6%\n",
      "   üîç Sample unmapped fields: Account, Account Code, Adjustment...\n",
      "\n",
      "üìã VendorPayments:\n",
      "   Total CSV columns: 28\n",
      "   Currently mapped: 20\n",
      "   Unmapped: 19\n",
      "   Coverage: 71.4%\n",
      "   üîç Sample unmapped fields: Bank Reference Number, Bill Amount, Bill Date...\n",
      "\n",
      "üìä OVERALL SUMMARY:\n",
      "   Entities analyzed: 9\n",
      "   Entities with unmapped fields: 9\n",
      "   Total unmapped fields: 469\n",
      "   Entities needing updates: Bills, Contacts, CreditNotes, CustomerPayments, Invoices, Items, PurchaseOrders, SalesOrders, VendorPayments\n",
      "\n",
      "‚úÖ READY TO UPDATE MAPPINGS\n",
      "   Found 469 additional fields to add to mappings.py\n"
     ]
    }
   ],
   "source": [
    "# Section 5: Summary of Unmapped Fields Analysis\n",
    "print(\"=== SUMMARY OF UNMAPPED FIELDS ANALYSIS ===\")\n",
    "print()\n",
    "\n",
    "total_unmapped = 0\n",
    "entities_with_unmapped = []\n",
    "\n",
    "for entity, analysis in csv_analysis.items():\n",
    "    if 'error' in analysis:\n",
    "        print(f\"‚ùå {entity}: Error during analysis\")\n",
    "        continue\n",
    "        \n",
    "    unmapped_count = analysis['unmapped_count']\n",
    "    total_csv_columns = analysis['total_csv_columns']\n",
    "    currently_mapped = analysis['currently_mapped']\n",
    "    \n",
    "    print(f\"üìã {entity}:\")\n",
    "    print(f\"   Total CSV columns: {total_csv_columns}\")\n",
    "    print(f\"   Currently mapped: {currently_mapped}\")\n",
    "    print(f\"   Unmapped: {unmapped_count}\")\n",
    "    print(f\"   Coverage: {(currently_mapped/total_csv_columns)*100:.1f}%\")\n",
    "    \n",
    "    if unmapped_count > 0:\n",
    "        entities_with_unmapped.append(entity)\n",
    "        total_unmapped += unmapped_count\n",
    "        print(f\"   üîç Sample unmapped fields: {', '.join(analysis['unmapped_columns'][:3])}...\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f\"üìä OVERALL SUMMARY:\")\n",
    "print(f\"   Entities analyzed: {len([e for e in csv_analysis.values() if 'error' not in e])}\")\n",
    "print(f\"   Entities with unmapped fields: {len(entities_with_unmapped)}\")\n",
    "print(f\"   Total unmapped fields: {total_unmapped}\")\n",
    "print(f\"   Entities needing updates: {', '.join(entities_with_unmapped)}\")\n",
    "\n",
    "if total_unmapped > 0:\n",
    "    print(f\"\\n‚úÖ READY TO UPDATE MAPPINGS\")\n",
    "    print(f\"   Found {total_unmapped} additional fields to add to mappings.py\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ NO UPDATES NEEDED\")\n",
    "    print(f\"   All CSV fields are already mapped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c1dad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAMPLE ANALYSIS: BILLS ENTITY ===\n",
      "CSV File: Bill.csv\n",
      "Total CSV columns: 64\n",
      "Currently mapped: 35\n",
      "Unmapped: 44\n",
      "\n",
      "üîç UNMAPPED FIELDS IN BILLS:\n",
      "   1. Account\n",
      "   2. Account Code\n",
      "   3. Accounts Payable\n",
      "   4. Adjustment\n",
      "   5. Adjustment Account\n",
      "   6. Adjustment Description\n",
      "   7. Approved By\n",
      "   8. Approved Date\n",
      "   9. Bill Status\n",
      "  10. Bill Type\n",
      "  11. Branch ID\n",
      "  12. Branch Name\n",
      "  13. CF.ChP Scheme Settlement Period\n",
      "  14. Created By\n",
      "  15. Customer Name\n",
      "  16. Description\n",
      "  17. Discount\n",
      "  18. Discount Account\n",
      "  19. Discount Account Code\n",
      "  20. Discount Amount\n",
      "  21. Discount Type\n",
      "  22. Entity Discount Amount\n",
      "  23. Entity Discount Percent\n",
      "  24. Is Billable\n",
      "  25. Is Discount Before Tax\n",
      "  26. Is Inclusive Tax\n",
      "  27. Is Landed Cost\n",
      "  28. Payment Terms\n",
      "  29. Payment Terms Label\n",
      "  30. Product ID\n",
      "  31. Purchase Order Number\n",
      "  32. PurchaseOrder\n",
      "  33. Region\n",
      "  34. SubTotal\n",
      "  35. Submitted By\n",
      "  36. Submitted Date\n",
      "  37. TDS Amount\n",
      "  38. TDS Name\n",
      "  39. TDS Percentage\n",
      "  40. TDS Type\n",
      "  41. Tax Amount\n",
      "  42. Usage unit\n",
      "  43. Vehicle\n",
      "  44. Vendor Notes\n",
      "\n",
      "üìù These 44 fields need to be added to BILLS_CSV_MAP\n",
      "\n",
      "üìã MAPPING ADDITIONS NEEDED:\n",
      "# Add to BILLS_CSV_MAP:\n",
      "    'Account': 'Account',\n",
      "    'Account Code': 'Account Code',\n",
      "    'Accounts Payable': 'Accounts Payable',\n",
      "    'Adjustment': 'Adjustment',\n",
      "    'Adjustment Account': 'Adjustment Account',\n",
      "    # ... and 39 more\n",
      "\n",
      "üîß CUSTOM FIELDS ANALYSIS:\n",
      "Found 1 likely custom fields in Bills:\n",
      "  - Customer Name\n"
     ]
    }
   ],
   "source": [
    "# Section 6: Sample Entity Analysis - Bills\n",
    "print(\"=== SAMPLE ANALYSIS: BILLS ENTITY ===\")\n",
    "\n",
    "if 'Bills' in csv_analysis and 'error' not in csv_analysis['Bills']:\n",
    "    bills_analysis = csv_analysis['Bills']\n",
    "    \n",
    "    print(f\"CSV File: {bills_analysis['csv_file']}\")\n",
    "    print(f\"Total CSV columns: {bills_analysis['total_csv_columns']}\")\n",
    "    print(f\"Currently mapped: {bills_analysis['currently_mapped']}\")\n",
    "    print(f\"Unmapped: {bills_analysis['unmapped_count']}\")\n",
    "    print()\n",
    "    \n",
    "    if bills_analysis['unmapped_columns']:\n",
    "        print(\"üîç UNMAPPED FIELDS IN BILLS:\")\n",
    "        for i, field in enumerate(bills_analysis['unmapped_columns'], 1):\n",
    "            print(f\"  {i:2d}. {field}\")\n",
    "        \n",
    "        print(f\"\\nüìù These {len(bills_analysis['unmapped_columns'])} fields need to be added to BILLS_CSV_MAP\")\n",
    "        \n",
    "        # Show what the mapping additions would look like\n",
    "        print(f\"\\nüìã MAPPING ADDITIONS NEEDED:\")\n",
    "        print(\"# Add to BILLS_CSV_MAP:\")\n",
    "        for field in bills_analysis['unmapped_columns'][:5]:  # Show first 5\n",
    "            print(f\"    '{field}': '{field}',\")\n",
    "        if len(bills_analysis['unmapped_columns']) > 5:\n",
    "            print(f\"    # ... and {len(bills_analysis['unmapped_columns']) - 5} more\")\n",
    "            \n",
    "    else:\n",
    "        print(\"‚úÖ No unmapped fields found in Bills\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Bills analysis not available or had errors\")\n",
    "\n",
    "# Quick check for custom fields pattern\n",
    "print(f\"\\nüîß CUSTOM FIELDS ANALYSIS:\")\n",
    "if 'Bills' in csv_analysis and 'unmapped_columns' in csv_analysis['Bills']:\n",
    "    custom_field_pattern = []\n",
    "    for field in csv_analysis['Bills']['unmapped_columns']:\n",
    "        if 'cf_' in field.lower() or 'custom' in field.lower():\n",
    "            custom_field_pattern.append(field)\n",
    "    \n",
    "    if custom_field_pattern:\n",
    "        print(f\"Found {len(custom_field_pattern)} likely custom fields in Bills:\")\n",
    "        for field in custom_field_pattern:\n",
    "            print(f\"  - {field}\")\n",
    "    else:\n",
    "        print(\"No obvious custom field patterns found (cf_, custom, etc.)\")\n",
    "else:\n",
    "    print(\"Unable to analyze custom field patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72f7d5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERATING UPDATED MAPPINGS ===\n",
      "\n",
      "Original mappings.py file size: 28273 characters\n",
      "Entities needing updates: 9\n",
      "Total new fields to add: 469\n",
      "\n",
      "üìã Bills: 44 new fields\n",
      "   - Account\n",
      "   - Account Code\n",
      "   - Accounts Payable\n",
      "   ... and 41 more\n",
      "\n",
      "üìã Contacts: 53 new fields\n",
      "   - Accounts Receivable\n",
      "   - Bank Account Payment\n",
      "   - Billing Attention\n",
      "   ... and 50 more\n",
      "\n",
      "üìã CreditNotes: 74 new fields\n",
      "   - Account\n",
      "   - Account Code\n",
      "   - Accounts Receivable\n",
      "   ... and 71 more\n",
      "\n",
      "üìã CustomerPayments: 18 new fields\n",
      "   - Amount Applied to Invoice\n",
      "   - Branch ID\n",
      "   - Branch Name\n",
      "   ... and 15 more\n",
      "\n",
      "üìã Invoices: 100 new fields\n",
      "   - 2Checkout\n",
      "   - Account\n",
      "   - Account Code\n",
      "   ... and 97 more\n",
      "\n",
      "üìã Items: 29 new fields\n",
      "   - Account\n",
      "   - Account Code\n",
      "   - CF.Item Location\n",
      "   ... and 26 more\n",
      "\n",
      "üìã PurchaseOrders: 64 new fields\n",
      "   - Account\n",
      "   - Account Code\n",
      "   - Address\n",
      "   ... and 61 more\n",
      "\n",
      "üìã SalesOrders: 68 new fields\n",
      "   - Account\n",
      "   - Account Code\n",
      "   - Adjustment\n",
      "   ... and 65 more\n",
      "\n",
      "üìã VendorPayments: 19 new fields\n",
      "   - Bank Reference Number\n",
      "   - Bill Amount\n",
      "   - Bill Date\n",
      "   ... and 16 more\n",
      "\n",
      "üîÑ PROCEEDING WITH MAPPINGS UPDATE...\n",
      "‚úÖ Added update header to file\n",
      "‚úÖ Ready to update 9 entity mappings\n"
     ]
    }
   ],
   "source": [
    "# Section 7: Generate Updated Mappings and Apply Changes\n",
    "print(\"=== GENERATING UPDATED MAPPINGS ===\")\n",
    "print()\n",
    "\n",
    "# Read the current mappings file\n",
    "with open(MAPPINGS_FILE, 'r', encoding='utf-8') as f:\n",
    "    mappings_content = f.read()\n",
    "\n",
    "print(f\"Original mappings.py file size: {len(mappings_content)} characters\")\n",
    "\n",
    "# Generate updates for each entity\n",
    "updates_needed = []\n",
    "total_new_fields = 0\n",
    "\n",
    "for entity, analysis in csv_analysis.items():\n",
    "    if 'error' in analysis or analysis['unmapped_count'] == 0:\n",
    "        continue\n",
    "    \n",
    "    updates_needed.append({\n",
    "        'entity': entity,\n",
    "        'new_fields': analysis['unmapped_columns'],\n",
    "        'count': analysis['unmapped_count']\n",
    "    })\n",
    "    total_new_fields += analysis['unmapped_count']\n",
    "\n",
    "print(f\"Entities needing updates: {len(updates_needed)}\")\n",
    "print(f\"Total new fields to add: {total_new_fields}\")\n",
    "print()\n",
    "\n",
    "for update in updates_needed:\n",
    "    entity = update['entity']\n",
    "    new_fields = update['new_fields']\n",
    "    count = update['count']\n",
    "    \n",
    "    print(f\"üìã {entity}: {count} new fields\")\n",
    "    for field in new_fields[:3]:  # Show first 3\n",
    "        print(f\"   - {field}\")\n",
    "    if count > 3:\n",
    "        print(f\"   ... and {count - 3} more\")\n",
    "    print()\n",
    "\n",
    "# Proceed with update if we have changes\n",
    "if updates_needed:\n",
    "    print(\"üîÑ PROCEEDING WITH MAPPINGS UPDATE...\")\n",
    "    \n",
    "    # Create updated content\n",
    "    updated_content = mappings_content\n",
    "    \n",
    "    # Add update header comment\n",
    "    update_timestamp = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    update_header = f\"\"\"\n",
    "# ============================================================================\n",
    "# MAPPINGS UPDATE - {update_timestamp}\n",
    "# ============================================================================\n",
    "# Added {total_new_fields} additional CSV fields (likely custom fields)\n",
    "# across {len(updates_needed)} entities. Fields maintain original CSV names.\n",
    "# Original backup: mappings_backup_2025-07-05_16-37-59.py\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Insert header after the existing docstring\n",
    "    docstring_end = updated_content.find('\"\"\"', updated_content.find('\"\"\"') + 3) + 3\n",
    "    updated_content = updated_content[:docstring_end] + update_header + updated_content[docstring_end:]\n",
    "    \n",
    "    print(\"‚úÖ Added update header to file\")\n",
    "    print(f\"‚úÖ Ready to update {len(updates_needed)} entity mappings\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No updates needed - all CSV fields are already mapped\")\n",
    "\n",
    "PROCEED_WITH_UPDATE = True  # Set to apply changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3986ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== APPLYING UPDATES TO MAPPINGS.PY ===\n",
      "\n",
      "üîÑ Updating BILLS_CSV_MAP for Bills...\n",
      "‚úÖ Added 44 fields to BILLS_CSV_MAP\n",
      "üîÑ Updating CONTACTS_CSV_MAP for Contacts...\n",
      "‚úÖ Added 53 fields to CONTACTS_CSV_MAP\n",
      "üîÑ Updating CREDIT_NOTES_CSV_MAP for CreditNotes...\n",
      "‚úÖ Added 74 fields to CREDIT_NOTES_CSV_MAP\n",
      "üîÑ Updating CUSTOMER_PAYMENTS_CSV_MAP for CustomerPayments...\n",
      "‚úÖ Added 18 fields to CUSTOMER_PAYMENTS_CSV_MAP\n",
      "üîÑ Updating INVOICE_CSV_MAP for Invoices...\n",
      "‚úÖ Added 100 fields to INVOICE_CSV_MAP\n",
      "üîÑ Updating ITEMS_CSV_MAP for Items...\n",
      "‚úÖ Added 29 fields to ITEMS_CSV_MAP\n",
      "üîÑ Updating PURCHASE_ORDERS_CSV_MAP for PurchaseOrders...\n",
      "‚úÖ Added 64 fields to PURCHASE_ORDERS_CSV_MAP\n",
      "üîÑ Updating SALES_ORDERS_CSV_MAP for SalesOrders...\n",
      "‚úÖ Added 68 fields to SALES_ORDERS_CSV_MAP\n",
      "üîÑ Updating VENDOR_PAYMENTS_CSV_MAP for VendorPayments...\n",
      "‚úÖ Added 19 fields to VENDOR_PAYMENTS_CSV_MAP\n",
      "\n",
      "üéâ SUCCESS! Updated mappings.py file\n",
      "   File size: 47883 characters\n",
      "   Added 469 new field mappings\n",
      "   Updated 9 entity mappings\n",
      "‚úÖ File verification successful\n",
      "\n",
      "üìã NEXT STEPS:\n",
      "1. Test the updated mappings with ETL pipeline\n",
      "2. Verify new fields are properly processed\n",
      "3. Update canonical schema if needed\n",
      "4. Commit changes to git\n"
     ]
    }
   ],
   "source": [
    "# Section 8: Apply Mappings Updates to File\n",
    "print(\"=== APPLYING UPDATES TO MAPPINGS.PY ===\")\n",
    "print()\n",
    "\n",
    "if 'updates_needed' in locals() and updates_needed and PROCEED_WITH_UPDATE:\n",
    "    \n",
    "    # For each entity that needs updates, modify the mapping\n",
    "    for update in updates_needed:\n",
    "        entity = update['entity']\n",
    "        new_fields = update['new_fields']\n",
    "        \n",
    "        # Find the mapping variable name\n",
    "        mapping_var_map = {\n",
    "            'Invoices': 'INVOICE_CSV_MAP',\n",
    "            'Items': 'ITEMS_CSV_MAP',\n",
    "            'Contacts': 'CONTACTS_CSV_MAP',\n",
    "            'Bills': 'BILLS_CSV_MAP',\n",
    "            'CustomerPayments': 'CUSTOMER_PAYMENTS_CSV_MAP',\n",
    "            'VendorPayments': 'VENDOR_PAYMENTS_CSV_MAP',\n",
    "            'SalesOrders': 'SALES_ORDERS_CSV_MAP',\n",
    "            'PurchaseOrders': 'PURCHASE_ORDERS_CSV_MAP',\n",
    "            'CreditNotes': 'CREDIT_NOTES_CSV_MAP'\n",
    "        }\n",
    "        \n",
    "        mapping_var = mapping_var_map.get(entity)\n",
    "        if not mapping_var:\n",
    "            print(f\"‚ö†Ô∏è  Skipping {entity} - no mapping variable found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"üîÑ Updating {mapping_var} for {entity}...\")\n",
    "        \n",
    "        # Find the mapping in the file content\n",
    "        mapping_start = updated_content.find(f\"{mapping_var} = {{\")\n",
    "        if mapping_start == -1:\n",
    "            print(f\"‚ùå Could not find {mapping_var} in file\")\n",
    "            continue\n",
    "        \n",
    "        # Find the end of the mapping (closing brace)\n",
    "        brace_count = 0\n",
    "        mapping_end = mapping_start\n",
    "        for i, char in enumerate(updated_content[mapping_start:]):\n",
    "            if char == '{':\n",
    "                brace_count += 1\n",
    "            elif char == '}':\n",
    "                brace_count -= 1\n",
    "                if brace_count == 0:\n",
    "                    mapping_end = mapping_start + i\n",
    "                    break\n",
    "        \n",
    "        if mapping_end == mapping_start:\n",
    "            print(f\"‚ùå Could not find end of {mapping_var}\")\n",
    "            continue\n",
    "        \n",
    "        # Insert new fields before the closing brace\n",
    "        new_mappings = []\n",
    "        for field in new_fields:\n",
    "            # Escape single quotes in field names\n",
    "            escaped_field = field.replace(\"'\", \"\\\\'\")\n",
    "            new_mappings.append(f\"    '{escaped_field}': '{escaped_field}',\")\n",
    "        \n",
    "        new_mappings_text = \"\\n\".join(new_mappings)\n",
    "        \n",
    "        # Insert the new mappings\n",
    "        insert_pos = mapping_end\n",
    "        updated_content = (\n",
    "            updated_content[:insert_pos] + \n",
    "            \"\\n    # Additional fields from CSV analysis\\n\" +\n",
    "            new_mappings_text + \"\\n\" +\n",
    "            updated_content[insert_pos:]\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Added {len(new_fields)} fields to {mapping_var}\")\n",
    "    \n",
    "    # Write the updated file\n",
    "    try:\n",
    "        with open(MAPPINGS_FILE, 'w', encoding='utf-8') as f:\n",
    "            f.write(updated_content)\n",
    "        \n",
    "        print(f\"\\nüéâ SUCCESS! Updated mappings.py file\")\n",
    "        print(f\"   File size: {len(updated_content)} characters\")\n",
    "        print(f\"   Added {total_new_fields} new field mappings\")\n",
    "        print(f\"   Updated {len(updates_needed)} entity mappings\")\n",
    "        \n",
    "        # Verify the file was written correctly\n",
    "        with open(MAPPINGS_FILE, 'r', encoding='utf-8') as f:\n",
    "            verification_content = f.read()\n",
    "        \n",
    "        if len(verification_content) == len(updated_content):\n",
    "            print(f\"‚úÖ File verification successful\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  File size mismatch - verification needed\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error writing file: {e}\")\n",
    "        print(\"File was not modified\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No updates applied - either no changes needed or PROCEED_WITH_UPDATE is False\")\n",
    "\n",
    "print(f\"\\nüìã NEXT STEPS:\")\n",
    "print(f\"1. Test the updated mappings with ETL pipeline\")\n",
    "print(f\"2. Verify new fields are properly processed\")\n",
    "print(f\"3. Update canonical schema if needed\")\n",
    "print(f\"4. Commit changes to git\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97012ba5",
   "metadata": {},
   "source": [
    "# CSV Field Analysis and Mappings Update\n",
    "## Date: 2025-07-05\n",
    "\n",
    "This notebook analyzes CSV files to identify additional fields that are not currently mapped in mappings.py.\n",
    "These are likely custom fields not documented in the Zoho API.\n",
    "\n",
    "### Objectives:\n",
    "1. Load all CSV files and examine their column structures\n",
    "2. Compare CSV columns with existing mappings\n",
    "3. Identify missing/unmapped fields\n",
    "4. Update mappings.py to include all CSV fields\n",
    "5. Maintain field names as they appear in CSV (custom fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d046bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Setup and Imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Any\n",
    "import re\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Working directory: {Path.cwd()}\")\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = Path.cwd().parent / 'data' / 'csv' / 'Nangsel Pioneers_2025-06-22'\n",
    "SRC_DIR = Path.cwd().parent / 'src'\n",
    "MAPPINGS_FILE = SRC_DIR / 'data_pipeline' / 'mappings.py'\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Data directory exists: {DATA_DIR.exists()}\")\n",
    "print(f\"Mappings file: {MAPPINGS_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d3174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2: Load Current Mappings\n",
    "from data_pipeline.mappings import (\n",
    "    CANONICAL_SCHEMA,\n",
    "    INVOICE_CSV_MAP,\n",
    "    ITEMS_CSV_MAP,\n",
    "    CONTACTS_CSV_MAP,\n",
    "    BILLS_CSV_MAP,\n",
    "    CUSTOMER_PAYMENTS_CSV_MAP,\n",
    "    VENDOR_PAYMENTS_CSV_MAP,\n",
    "    SALES_ORDERS_CSV_MAP,\n",
    "    PURCHASE_ORDERS_CSV_MAP,\n",
    "    CREDIT_NOTES_CSV_MAP,\n",
    "    get_entity_csv_mapping\n",
    ")\n",
    "\n",
    "print(\"Current mappings loaded successfully!\")\n",
    "print(f\"Total entities in schema: {len(CANONICAL_SCHEMA)}\")\n",
    "\n",
    "# Map entity names to their CSV mappings\n",
    "ENTITY_MAPPINGS = {\n",
    "    'Invoices': INVOICE_CSV_MAP,\n",
    "    'Items': ITEMS_CSV_MAP,\n",
    "    'Contacts': CONTACTS_CSV_MAP,\n",
    "    'Bills': BILLS_CSV_MAP,\n",
    "    'CustomerPayments': CUSTOMER_PAYMENTS_CSV_MAP,\n",
    "    'VendorPayments': VENDOR_PAYMENTS_CSV_MAP,\n",
    "    'SalesOrders': SALES_ORDERS_CSV_MAP,\n",
    "    'PurchaseOrders': PURCHASE_ORDERS_CSV_MAP,\n",
    "    'CreditNotes': CREDIT_NOTES_CSV_MAP\n",
    "}\n",
    "\n",
    "print(\"Entity mappings configured:\")\n",
    "for entity, mapping in ENTITY_MAPPINGS.items():\n",
    "    print(f\"  {entity}: {len(mapping)} mapped fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a33c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3: Discover CSV Files and Map to Entities\n",
    "if DATA_DIR.exists():\n",
    "    csv_files = list(DATA_DIR.glob('*.csv'))\n",
    "    print(f\"Found {len(csv_files)} CSV files:\")\n",
    "    \n",
    "    # Map CSV files to entity names\n",
    "    csv_to_entity_map = {\n",
    "        'Invoice.csv': 'Invoices',\n",
    "        'Item.csv': 'Items', \n",
    "        'Contacts.csv': 'Contacts',\n",
    "        'Bill.csv': 'Bills',\n",
    "        'Customer_Payment.csv': 'CustomerPayments',\n",
    "        'Vendor_Payment.csv': 'VendorPayments',\n",
    "        'Sales_Order.csv': 'SalesOrders',\n",
    "        'Purchase_Order.csv': 'PurchaseOrders',\n",
    "        'Credit_Note.csv': 'CreditNotes'\n",
    "    }\n",
    "    \n",
    "    available_files = {}\n",
    "    for csv_file in csv_files:\n",
    "        file_name = csv_file.name\n",
    "        entity = csv_to_entity_map.get(file_name)\n",
    "        if entity:\n",
    "            available_files[entity] = csv_file\n",
    "            print(f\"  ‚úÖ {file_name} -> {entity}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  {file_name} -> No mapping found\")\n",
    "    \n",
    "    print(f\"\\nMapped {len(available_files)} CSV files to entities\")\n",
    "else:\n",
    "    print(f\"‚ùå Data directory not found: {DATA_DIR}\")\n",
    "    available_files = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b3aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: Analyze CSV Column Structures\n",
    "csv_analysis = {}\n",
    "\n",
    "print(\"=== ANALYZING CSV COLUMN STRUCTURES ===\")\n",
    "print()\n",
    "\n",
    "for entity, csv_file in available_files.items():\n",
    "    print(f\"--- Analyzing {entity} ({csv_file.name}) ---\")\n",
    "    \n",
    "    try:\n",
    "        # Load CSV to get column names (just first few rows for efficiency)\n",
    "        df = pd.read_csv(csv_file, nrows=5)\n",
    "        csv_columns = list(df.columns)\n",
    "        \n",
    "        # Get current mapping for this entity\n",
    "        current_mapping = ENTITY_MAPPINGS.get(entity, {})\n",
    "        mapped_columns = set(current_mapping.keys())\n",
    "        csv_columns_set = set(csv_columns)\n",
    "        \n",
    "        # Find unmapped columns\n",
    "        unmapped_columns = csv_columns_set - mapped_columns\n",
    "        \n",
    "        # Find mapped columns that don't exist in CSV\n",
    "        missing_in_csv = mapped_columns - csv_columns_set\n",
    "        \n",
    "        csv_analysis[entity] = {\n",
    "            'csv_file': csv_file.name,\n",
    "            'total_csv_columns': len(csv_columns),\n",
    "            'csv_columns': csv_columns,\n",
    "            'currently_mapped': len(mapped_columns),\n",
    "            'mapped_columns': sorted(mapped_columns),\n",
    "            'unmapped_count': len(unmapped_columns),\n",
    "            'unmapped_columns': sorted(unmapped_columns),\n",
    "            'missing_in_csv_count': len(missing_in_csv),\n",
    "            'missing_in_csv': sorted(missing_in_csv)\n",
    "        }\n",
    "        \n",
    "        print(f\"  Total CSV columns: {len(csv_columns)}\")\n",
    "        print(f\"  Currently mapped: {len(mapped_columns)}\")\n",
    "        print(f\"  Unmapped columns: {len(unmapped_columns)}\")\n",
    "        \n",
    "        if unmapped_columns:\n",
    "            print(f\"  üîç Unmapped fields found:\")\n",
    "            for col in sorted(unmapped_columns)[:10]:  # Show first 10\n",
    "                print(f\"    - {col}\")\n",
    "            if len(unmapped_columns) > 10:\n",
    "                print(f\"    ... and {len(unmapped_columns) - 10} more\")\n",
    "        \n",
    "        if missing_in_csv:\n",
    "            print(f\"  ‚ö†Ô∏è  Mapped but not in CSV: {len(missing_in_csv)}\")\n",
    "            for col in sorted(missing_in_csv)[:5]:\n",
    "                print(f\"    - {col}\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error analyzing {csv_file.name}: {e}\")\n",
    "        csv_analysis[entity] = {'error': str(e)}\n",
    "        print()\n",
    "\n",
    "print(f\"Analysis completed for {len(csv_analysis)} entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1593414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5: Detailed Analysis of Unmapped Fields\n",
    "print(\"=== DETAILED UNMAPPED FIELDS ANALYSIS ===\")\n",
    "print()\n",
    "\n",
    "total_unmapped = 0\n",
    "all_unmapped_fields = {}\n",
    "\n",
    "for entity, analysis in csv_analysis.items():\n",
    "    if 'error' in analysis:\n",
    "        continue\n",
    "        \n",
    "    unmapped = analysis['unmapped_columns']\n",
    "    if unmapped:\n",
    "        print(f\"--- {entity} ({analysis['unmapped_count']} unmapped fields) ---\")\n",
    "        total_unmapped += len(unmapped)\n",
    "        all_unmapped_fields[entity] = unmapped\n",
    "        \n",
    "        # Categorize fields by likely type\n",
    "        custom_fields = []\n",
    "        system_fields = []\n",
    "        unknown_fields = []\n",
    "        \n",
    "        for field in unmapped:\n",
    "            field_lower = field.lower()\n",
    "            if any(keyword in field_lower for keyword in ['cf_', 'custom', 'field']):\n",
    "                custom_fields.append(field)\n",
    "            elif any(keyword in field_lower for keyword in ['id', 'time', 'date', 'status', 'number']):\n",
    "                system_fields.append(field)\n",
    "            else:\n",
    "                unknown_fields.append(field)\n",
    "        \n",
    "        if custom_fields:\n",
    "            print(f\"  üîß Likely Custom Fields ({len(custom_fields)}):\")\n",
    "            for field in custom_fields:\n",
    "                print(f\"    - {field}\")\n",
    "        \n",
    "        if system_fields:\n",
    "            print(f\"  ‚öôÔ∏è  Likely System Fields ({len(system_fields)}):\")\n",
    "            for field in system_fields:\n",
    "                print(f\"    - {field}\")\n",
    "        \n",
    "        if unknown_fields:\n",
    "            print(f\"  ‚ùì Other Fields ({len(unknown_fields)}):\")\n",
    "            for field in unknown_fields:\n",
    "                print(f\"    - {field}\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "print(f\"üìä SUMMARY:\")\n",
    "print(f\"Total entities analyzed: {len([e for e in csv_analysis.values() if 'error' not in e])}\")\n",
    "print(f\"Entities with unmapped fields: {len(all_unmapped_fields)}\")\n",
    "print(f\"Total unmapped fields across all entities: {total_unmapped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a673dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6: Sample Data Analysis for Unmapped Fields\n",
    "print(\"=== SAMPLE DATA ANALYSIS FOR UNMAPPED FIELDS ===\")\n",
    "print()\n",
    "\n",
    "for entity, unmapped_fields in all_unmapped_fields.items():\n",
    "    if not unmapped_fields:\n",
    "        continue\n",
    "        \n",
    "    csv_file = available_files[entity]\n",
    "    print(f\"--- {entity} Sample Data ---\")\n",
    "    \n",
    "    try:\n",
    "        # Load sample data to understand field types and content\n",
    "        df = pd.read_csv(csv_file, nrows=10)\n",
    "        \n",
    "        for field in unmapped_fields[:5]:  # Show first 5 unmapped fields\n",
    "            if field in df.columns:\n",
    "                non_null_values = df[field].dropna()\n",
    "                unique_values = non_null_values.nunique()\n",
    "                sample_values = non_null_values.head(3).tolist()\n",
    "                \n",
    "                print(f\"  üìã {field}:\")\n",
    "                print(f\"    Non-null values: {len(non_null_values)}/10\")\n",
    "                print(f\"    Unique values: {unique_values}\")\n",
    "                print(f\"    Sample values: {sample_values}\")\n",
    "                \n",
    "                # Suggest data type\n",
    "                if non_null_values.empty:\n",
    "                    suggested_type = 'TEXT'  # Default for empty\n",
    "                elif pd.api.types.is_numeric_dtype(df[field]):\n",
    "                    suggested_type = 'REAL' if any('.' in str(v) for v in sample_values) else 'INTEGER'\n",
    "                else:\n",
    "                    suggested_type = 'TEXT'\n",
    "                \n",
    "                print(f\"    Suggested type: {suggested_type}\")\n",
    "                print()\n",
    "        \n",
    "        if len(unmapped_fields) > 5:\n",
    "            print(f\"  ... and {len(unmapped_fields) - 5} more unmapped fields\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error analyzing sample data: {e}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25afbcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 7: Generate Updated Mappings Structure\n",
    "print(\"=== GENERATING UPDATED MAPPINGS STRUCTURE ===\")\n",
    "print()\n",
    "\n",
    "updated_mappings = {}\n",
    "\n",
    "for entity, analysis in csv_analysis.items():\n",
    "    if 'error' in analysis:\n",
    "        continue\n",
    "    \n",
    "    print(f\"--- Generating updated mapping for {entity} ---\")\n",
    "    \n",
    "    # Start with current mapping\n",
    "    current_mapping = ENTITY_MAPPINGS.get(entity, {}).copy()\n",
    "    \n",
    "    # Add unmapped fields (keep same name as CSV)\n",
    "    unmapped_fields = analysis['unmapped_columns']\n",
    "    \n",
    "    for field in unmapped_fields:\n",
    "        # For unmapped fields, map CSV field name to itself (canonical name = CSV name)\n",
    "        current_mapping[field] = field\n",
    "    \n",
    "    updated_mappings[entity] = current_mapping\n",
    "    \n",
    "    print(f\"  Original mapped fields: {analysis['currently_mapped']}\")\n",
    "    print(f\"  Added unmapped fields: {len(unmapped_fields)}\")\n",
    "    print(f\"  Total fields in updated mapping: {len(current_mapping)}\")\n",
    "    \n",
    "    if unmapped_fields:\n",
    "        print(f\"  Added fields:\")\n",
    "        for field in unmapped_fields[:10]:  # Show first 10\n",
    "            print(f\"    '{field}': '{field}',\")\n",
    "        if len(unmapped_fields) > 10:\n",
    "            print(f\"    ... and {len(unmapped_fields) - 10} more\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f\"Updated mappings generated for {len(updated_mappings)} entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdae5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 8: Update Schema with New Fields\n",
    "print(\"=== UPDATING CANONICAL SCHEMA WITH NEW FIELDS ===\")\n",
    "print()\n",
    "\n",
    "updated_schema = {}\n",
    "\n",
    "for entity in CANONICAL_SCHEMA.keys():\n",
    "    print(f\"--- Updating schema for {entity} ---\")\n",
    "    \n",
    "    # Copy current schema\n",
    "    current_schema = CANONICAL_SCHEMA[entity].copy()\n",
    "    \n",
    "    # Get unmapped fields for this entity\n",
    "    if entity in all_unmapped_fields:\n",
    "        unmapped_fields = all_unmapped_fields[entity]\n",
    "        \n",
    "        # Add unmapped fields to both header and line item columns as needed\n",
    "        header_columns = current_schema['header_columns'].copy()\n",
    "        line_items_columns = current_schema.get('line_items_columns', {}).copy()\n",
    "        \n",
    "        # Analyze which fields belong to header vs line items\n",
    "        if entity in available_files:\n",
    "            csv_file = available_files[entity]\n",
    "            try:\n",
    "                df = pd.read_csv(csv_file, nrows=10)\n",
    "                \n",
    "                # Simple heuristic: fields with repeating values likely belong to line items\n",
    "                for field in unmapped_fields:\n",
    "                    if field in df.columns:\n",
    "                        # Default to TEXT type for new fields\n",
    "                        field_type = 'TEXT'\n",
    "                        \n",
    "                        # Try to infer better type\n",
    "                        non_null_values = df[field].dropna()\n",
    "                        if not non_null_values.empty:\n",
    "                            if pd.api.types.is_numeric_dtype(df[field]):\n",
    "                                field_type = 'REAL'\n",
    "                            elif pd.api.types.is_integer_dtype(df[field]):\n",
    "                                field_type = 'INTEGER'\n",
    "                        \n",
    "                        # For now, add all unmapped fields to header columns\n",
    "                        # (More sophisticated logic would be needed to determine line item fields)\n",
    "                        header_columns[field] = field_type\n",
    "                        \n",
    "                        print(f\"  Added to header: {field} ({field_type})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö†Ô∏è  Error processing CSV data: {e}\")\n",
    "                # Fallback: add as TEXT fields\n",
    "                for field in unmapped_fields:\n",
    "                    header_columns[field] = 'TEXT'\n",
    "                    print(f\"  Added to header (fallback): {field} (TEXT)\")\n",
    "        \n",
    "        # Update the schema\n",
    "        current_schema['header_columns'] = header_columns\n",
    "        current_schema['line_items_columns'] = line_items_columns\n",
    "        \n",
    "        print(f\"  Original header columns: {len(CANONICAL_SCHEMA[entity]['header_columns'])}\")\n",
    "        print(f\"  Updated header columns: {len(header_columns)}\")\n",
    "        print(f\"  Added: {len(unmapped_fields)} new fields\")\n",
    "    else:\n",
    "        print(f\"  No unmapped fields found - schema unchanged\")\n",
    "    \n",
    "    updated_schema[entity] = current_schema\n",
    "    print()\n",
    "\n",
    "print(f\"Schema updates completed for {len(updated_schema)} entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d009ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 9: Generate Updated Mappings.py Content\n",
    "print(\"=== GENERATING UPDATED MAPPINGS.PY CONTENT ===\")\n",
    "print()\n",
    "\n",
    "# Read the original mappings file to preserve structure and comments\n",
    "with open(MAPPINGS_FILE, 'r', encoding='utf-8') as f:\n",
    "    original_content = f.read()\n",
    "\n",
    "print(f\"Original mappings.py size: {len(original_content)} characters\")\n",
    "\n",
    "# Create backup content summary\n",
    "backup_summary = f\"\"\"\n",
    "# ============================================================================\n",
    "# MAPPINGS UPDATE SUMMARY - {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "# ============================================================================\n",
    "# This file was automatically updated to include additional CSV fields\n",
    "# that were not previously mapped (likely custom fields).\n",
    "#\n",
    "# Update Summary:\n",
    "\"\"\"\n",
    "\n",
    "total_added_fields = 0\n",
    "for entity, analysis in csv_analysis.items():\n",
    "    if 'error' not in analysis and analysis['unmapped_count'] > 0:\n",
    "        total_added_fields += analysis['unmapped_count']\n",
    "        backup_summary += f\"# - {entity}: Added {analysis['unmapped_count']} fields\\n\"\n",
    "\n",
    "backup_summary += f\"#\\n# Total new fields added: {total_added_fields}\\n\"\n",
    "backup_summary += f\"# Original backup: mappings_backup_2025-07-05_16-37-59.py\\n\"\n",
    "backup_summary += f\"# ============================================================================\\n\\n\"\n",
    "\n",
    "print(f\"Total new fields to be added: {total_added_fields}\")\n",
    "print(\"\\nUpdate summary prepared for file header\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 10: Write Updated Mappings File\n",
    "print(\"=== WRITING UPDATED MAPPINGS.PY FILE ===\")\n",
    "print()\n",
    "\n",
    "# For this demonstration, let's create the updated content structure\n",
    "# In practice, you'd want to programmatically update the file\n",
    "\n",
    "print(\"üìã IMPLEMENTATION PLAN:\")\n",
    "print(\"1. ‚úÖ Backup original mappings.py file\")\n",
    "print(\"2. ‚úÖ Analyze CSV files for unmapped fields\")\n",
    "print(\"3. ‚úÖ Generate updated mapping structures\")\n",
    "print(\"4. ‚úÖ Identify new schema requirements\")\n",
    "print(\"5. üîÑ Update mappings.py with new fields\")\n",
    "print(\"6. üîÑ Test updated mappings with ETL pipeline\")\n",
    "\n",
    "print(\"\\nüìä SUMMARY OF CHANGES NEEDED:\")\n",
    "for entity, analysis in csv_analysis.items():\n",
    "    if 'error' not in analysis and analysis['unmapped_count'] > 0:\n",
    "        print(f\"\\n{entity}:\")\n",
    "        print(f\"  - Current mapped fields: {analysis['currently_mapped']}\")\n",
    "        print(f\"  - Fields to add: {analysis['unmapped_count']}\")\n",
    "        print(f\"  - New total: {analysis['currently_mapped'] + analysis['unmapped_count']}\")\n",
    "        \n",
    "        # Show specific fields to add\n",
    "        if analysis['unmapped_columns']:\n",
    "            print(f\"  - Fields to add: {', '.join(analysis['unmapped_columns'][:5])}{'...' if len(analysis['unmapped_columns']) > 5 else ''}\")\n",
    "\n",
    "print(f\"\\nüéØ NEXT STEPS:\")\n",
    "print(\"1. Review the identified unmapped fields above\")\n",
    "print(\"2. Confirm which fields should be added to mappings\")\n",
    "print(\"3. Run the update process to modify mappings.py\")\n",
    "print(\"4. Test the updated mappings with ETL pipeline\")\n",
    "\n",
    "# Set flag for whether to proceed with file update\n",
    "PROCEED_WITH_UPDATE = True  # Set to True to actually update the file\n",
    "\n",
    "if PROCEED_WITH_UPDATE:\n",
    "    print(\"\\n‚ö†Ô∏è  READY TO UPDATE MAPPINGS.PY\")\n",
    "    print(\"The next cell will actually modify the file.\")\n",
    "else:\n",
    "    print(\"\\n‚úã UPDATE PAUSED\")\n",
    "    print(\"Set PROCEED_WITH_UPDATE = True to update the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c8786f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHECKING SPECIFIC TARGET ENTITIES ===\n",
      "\n",
      "Target entities to analyze:\n",
      "  - Invoices\n",
      "  - Items\n",
      "  - Contacts\n",
      "  - Bills\n",
      "  - Organizations\n",
      "  - CustomerPayments\n",
      "  - VendorPayments\n",
      "  - SalesOrders\n",
      "  - PurchaseOrders\n",
      "  - CreditNotes\n",
      "\n",
      "üìã Invoices:\n",
      "   CSV file: Invoice.csv\n",
      "   Total CSV columns: 122\n",
      "   Currently mapped: 37\n",
      "   Unmapped fields: 100\n",
      "   Sample unmapped: 2Checkout, Account, Account Code...\n",
      "\n",
      "üìã Items:\n",
      "   CSV file: Item.csv\n",
      "   Total CSV columns: 41\n",
      "   Currently mapped: 24\n",
      "   Unmapped fields: 29\n",
      "   Sample unmapped: Account, Account Code, CF.Item Location...\n",
      "\n",
      "üìã Contacts:\n",
      "   CSV file: Contacts.csv\n",
      "   Total CSV columns: 72\n",
      "   Currently mapped: 23\n",
      "   Unmapped fields: 53\n",
      "   Sample unmapped: Accounts Receivable, Bank Account Payment, Billing Attention...\n",
      "\n",
      "üìã Bills:\n",
      "   CSV file: Bill.csv\n",
      "   Total CSV columns: 64\n",
      "   Currently mapped: 35\n",
      "   Unmapped fields: 44\n",
      "   Sample unmapped: Account, Account Code, Accounts Payable...\n",
      "\n",
      "‚ùå Organizations: No CSV file found\n",
      "üìã CustomerPayments:\n",
      "   CSV file: Customer_Payment.csv\n",
      "   Total CSV columns: 29\n",
      "   Currently mapped: 20\n",
      "   Unmapped fields: 18\n",
      "   Sample unmapped: Amount Applied to Invoice, Branch ID, Branch Name...\n",
      "\n",
      "üìã VendorPayments:\n",
      "   CSV file: Vendor_Payment.csv\n",
      "   Total CSV columns: 28\n",
      "   Currently mapped: 20\n",
      "   Unmapped fields: 19\n",
      "   Sample unmapped: Bank Reference Number, Bill Amount, Bill Date...\n",
      "\n",
      "üìã SalesOrders:\n",
      "   CSV file: Sales_Order.csv\n",
      "   Total CSV columns: 83\n",
      "   Currently mapped: 32\n",
      "   Unmapped fields: 68\n",
      "   Sample unmapped: Account, Account Code, Adjustment...\n",
      "\n",
      "üìã PurchaseOrders:\n",
      "   CSV file: Purchase_Order.csv\n",
      "   Total CSV columns: 75\n",
      "   Currently mapped: 32\n",
      "   Unmapped fields: 64\n",
      "   Sample unmapped: Account, Account Code, Address...\n",
      "\n",
      "üìã CreditNotes:\n",
      "   CSV file: Credit_Note.csv\n",
      "   Total CSV columns: 87\n",
      "   Currently mapped: 31\n",
      "   Unmapped fields: 74\n",
      "   Sample unmapped: Account, Account Code, Accounts Receivable...\n",
      "\n",
      "üìä SUMMARY FOR TARGET ENTITIES:\n",
      "   Entities with CSV files: 9\n",
      "   Total unmapped fields: 469\n",
      "\n",
      "üìã BREAKDOWN BY ENTITY:\n",
      "   Invoices: 100 new fields\n",
      "   Items: 29 new fields\n",
      "   Contacts: 53 new fields\n",
      "   Bills: 44 new fields\n",
      "   CustomerPayments: 18 new fields\n",
      "   VendorPayments: 19 new fields\n",
      "   SalesOrders: 68 new fields\n",
      "   PurchaseOrders: 64 new fields\n",
      "   CreditNotes: 74 new fields\n"
     ]
    }
   ],
   "source": [
    "# Section 11: Check Specific Target Entities\n",
    "print(\"=== CHECKING SPECIFIC TARGET ENTITIES ===\")\n",
    "print()\n",
    "\n",
    "# List of specific entities to focus on\n",
    "target_entities = [\n",
    "    'Invoices',\n",
    "    'Items', \n",
    "    'Contacts',\n",
    "    'Bills',\n",
    "    'Organizations',\n",
    "    'CustomerPayments',\n",
    "    'VendorPayments',\n",
    "    'SalesOrders',\n",
    "    'PurchaseOrders',\n",
    "    'CreditNotes'\n",
    "]\n",
    "\n",
    "print(\"Target entities to analyze:\")\n",
    "for entity in target_entities:\n",
    "    print(f\"  - {entity}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Check which of these entities have CSV files and analysis\n",
    "target_analysis = {}\n",
    "total_target_fields = 0\n",
    "\n",
    "for entity in target_entities:\n",
    "    if entity in csv_analysis and 'error' not in csv_analysis[entity]:\n",
    "        analysis = csv_analysis[entity]\n",
    "        target_analysis[entity] = analysis\n",
    "        total_target_fields += analysis['unmapped_count']\n",
    "        \n",
    "        print(f\"üìã {entity}:\")\n",
    "        print(f\"   CSV file: {analysis.get('csv_file', 'N/A')}\")\n",
    "        print(f\"   Total CSV columns: {analysis['total_csv_columns']}\")\n",
    "        print(f\"   Currently mapped: {analysis['currently_mapped']}\")\n",
    "        print(f\"   Unmapped fields: {analysis['unmapped_count']}\")\n",
    "        \n",
    "        if analysis['unmapped_count'] > 0:\n",
    "            print(f\"   Sample unmapped: {', '.join(analysis['unmapped_columns'][:3])}...\")\n",
    "        \n",
    "        print()\n",
    "    elif entity in available_files:\n",
    "        print(f\"‚ö†Ô∏è  {entity}: CSV file found but analysis failed\")\n",
    "    else:\n",
    "        print(f\"‚ùå {entity}: No CSV file found\")\n",
    "\n",
    "print(f\"üìä SUMMARY FOR TARGET ENTITIES:\")\n",
    "print(f\"   Entities with CSV files: {len(target_analysis)}\")\n",
    "print(f\"   Total unmapped fields: {total_target_fields}\")\n",
    "\n",
    "if target_analysis:\n",
    "    print(f\"\\nüìã BREAKDOWN BY ENTITY:\")\n",
    "    for entity, analysis in target_analysis.items():\n",
    "        if analysis['unmapped_count'] > 0:\n",
    "            print(f\"   {entity}: {analysis['unmapped_count']} new fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42639792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONCISE SUMMARY FOR TARGET ENTITIES ===\n",
      "\n",
      "üìä QUICK SUMMARY:\n",
      "   Target entities with CSV files: 9/10\n",
      "   Total new fields needed: 469\n",
      "\n",
      "üìã Entities needing field additions:\n",
      "   - Invoices: 100\n",
      "   - Items: 29\n",
      "   - Contacts: 53\n",
      "   - Bills: 44\n",
      "   - CustomerPayments: 18\n",
      "   - VendorPayments: 19\n",
      "   - SalesOrders: 68\n",
      "   - PurchaseOrders: 64\n",
      "   - CreditNotes: 74\n",
      "\n",
      "üéØ RESULT: Need to add 469 additional fields across 9 entities\n"
     ]
    }
   ],
   "source": [
    "# Section 12: Concise Summary for Target Entities\n",
    "print(\"=== CONCISE SUMMARY FOR TARGET ENTITIES ===\")\n",
    "print()\n",
    "\n",
    "target_entities = [\n",
    "    'Invoices', 'Items', 'Contacts', 'Bills', 'Organizations',\n",
    "    'CustomerPayments', 'VendorPayments', 'SalesOrders', \n",
    "    'PurchaseOrders', 'CreditNotes'\n",
    "]\n",
    "\n",
    "entities_found = 0\n",
    "total_new_fields = 0\n",
    "breakdown = []\n",
    "\n",
    "for entity in target_entities:\n",
    "    if entity in csv_analysis and 'error' not in csv_analysis[entity]:\n",
    "        analysis = csv_analysis[entity]\n",
    "        entities_found += 1\n",
    "        new_fields = analysis['unmapped_count']\n",
    "        total_new_fields += new_fields\n",
    "        \n",
    "        if new_fields > 0:\n",
    "            breakdown.append(f\"{entity}: {new_fields}\")\n",
    "\n",
    "print(f\"üìä QUICK SUMMARY:\")\n",
    "print(f\"   Target entities with CSV files: {entities_found}/10\")\n",
    "print(f\"   Total new fields needed: {total_new_fields}\")\n",
    "print()\n",
    "\n",
    "if breakdown:\n",
    "    print(\"üìã Entities needing field additions:\")\n",
    "    for item in breakdown:\n",
    "        print(f\"   - {item}\")\n",
    "else:\n",
    "    print(\"‚úÖ All target entities are fully mapped!\")\n",
    "\n",
    "print(f\"\\nüéØ RESULT: Need to add {total_new_fields} additional fields across {len(breakdown)} entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a975a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED ENTITY STATUS CHECK ===\n",
      "\n",
      "üìã STATUS FOR EACH TARGET ENTITY:\n",
      "\n",
      "--- Invoices ---\n",
      "   ‚úÖ CSV found: Invoice.csv\n",
      "   üìä Total CSV columns: 122\n",
      "   ‚úÖ Currently mapped: 37\n",
      "   üîç Need to add: 100 fields\n",
      "   üìà Current coverage: 30.3%\n",
      "\n",
      "--- Items ---\n",
      "   ‚úÖ CSV found: Item.csv\n",
      "   üìä Total CSV columns: 41\n",
      "   ‚úÖ Currently mapped: 24\n",
      "   üîç Need to add: 29 fields\n",
      "   üìà Current coverage: 58.5%\n",
      "\n",
      "--- Contacts ---\n",
      "   ‚úÖ CSV found: Contacts.csv\n",
      "   üìä Total CSV columns: 72\n",
      "   ‚úÖ Currently mapped: 23\n",
      "   üîç Need to add: 53 fields\n",
      "   üìà Current coverage: 31.9%\n",
      "\n",
      "--- Bills ---\n",
      "   ‚úÖ CSV found: Bill.csv\n",
      "   üìä Total CSV columns: 64\n",
      "   ‚úÖ Currently mapped: 35\n",
      "   üîç Need to add: 44 fields\n",
      "   üìà Current coverage: 54.7%\n",
      "\n",
      "--- Organizations ---\n",
      "   ‚ùå No CSV file found\n",
      "   üí° Available CSV files:\n",
      "      - Bill.csv\n",
      "      - Contacts.csv\n",
      "      - Credit_Note.csv\n",
      "      - Customer_Payment.csv\n",
      "      - Invoice.csv\n",
      "      - Item.csv\n",
      "      - Purchase_Order.csv\n",
      "      - Sales_Order.csv\n",
      "      - Vendor_Payment.csv\n",
      "\n",
      "--- CustomerPayments ---\n",
      "   ‚úÖ CSV found: Customer_Payment.csv\n",
      "   üìä Total CSV columns: 29\n",
      "   ‚úÖ Currently mapped: 20\n",
      "   üîç Need to add: 18 fields\n",
      "   üìà Current coverage: 69.0%\n",
      "\n",
      "--- VendorPayments ---\n",
      "   ‚úÖ CSV found: Vendor_Payment.csv\n",
      "   üìä Total CSV columns: 28\n",
      "   ‚úÖ Currently mapped: 20\n",
      "   üîç Need to add: 19 fields\n",
      "   üìà Current coverage: 71.4%\n",
      "\n",
      "--- SalesOrders ---\n",
      "   ‚úÖ CSV found: Sales_Order.csv\n",
      "   üìä Total CSV columns: 83\n",
      "   ‚úÖ Currently mapped: 32\n",
      "   üîç Need to add: 68 fields\n",
      "   üìà Current coverage: 38.6%\n",
      "\n",
      "--- PurchaseOrders ---\n",
      "   ‚úÖ CSV found: Purchase_Order.csv\n",
      "   üìä Total CSV columns: 75\n",
      "   ‚úÖ Currently mapped: 32\n",
      "   üîç Need to add: 64 fields\n",
      "   üìà Current coverage: 42.7%\n",
      "\n",
      "--- CreditNotes ---\n",
      "   ‚úÖ CSV found: Credit_Note.csv\n",
      "   üìä Total CSV columns: 87\n",
      "   ‚úÖ Currently mapped: 31\n",
      "   üîç Need to add: 74 fields\n",
      "   üìà Current coverage: 35.6%\n",
      "\n",
      "üîç CHECKING FOR ORGANIZATIONS-RELATED FILES:\n",
      "   No organization-related CSV files found\n",
      "\n",
      "üìä SUMMARY:\n",
      "   Target entities: 10\n",
      "   CSV files found: 9\n",
      "   Missing CSV files: 1\n",
      "   Total new fields to add: 469\n"
     ]
    }
   ],
   "source": [
    "# Section 13: Detailed Entity Status Check\n",
    "print(\"=== DETAILED ENTITY STATUS CHECK ===\")\n",
    "print()\n",
    "\n",
    "target_entities = [\n",
    "    'Invoices', 'Items', 'Contacts', 'Bills', 'Organizations',\n",
    "    'CustomerPayments', 'VendorPayments', 'SalesOrders', \n",
    "    'PurchaseOrders', 'CreditNotes'\n",
    "]\n",
    "\n",
    "print(\"üìã STATUS FOR EACH TARGET ENTITY:\")\n",
    "print()\n",
    "\n",
    "for entity in target_entities:\n",
    "    print(f\"--- {entity} ---\")\n",
    "    \n",
    "    if entity in csv_analysis and 'error' not in csv_analysis[entity]:\n",
    "        analysis = csv_analysis[entity]\n",
    "        print(f\"   ‚úÖ CSV found: {analysis['csv_file']}\")\n",
    "        print(f\"   üìä Total CSV columns: {analysis['total_csv_columns']}\")\n",
    "        print(f\"   ‚úÖ Currently mapped: {analysis['currently_mapped']}\")\n",
    "        print(f\"   üîç Need to add: {analysis['unmapped_count']} fields\")\n",
    "        \n",
    "        # Show coverage percentage\n",
    "        total_cols = analysis['total_csv_columns']\n",
    "        mapped_cols = analysis['currently_mapped']\n",
    "        coverage = (mapped_cols / total_cols * 100) if total_cols > 0 else 0\n",
    "        print(f\"   üìà Current coverage: {coverage:.1f}%\")\n",
    "        \n",
    "    elif entity in available_files:\n",
    "        print(f\"   ‚ö†Ô∏è  CSV found but analysis failed\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå No CSV file found\")\n",
    "        # Check what CSV files we do have\n",
    "        print(f\"   üí° Available CSV files:\")\n",
    "        for file_entity, csv_path in available_files.items():\n",
    "            print(f\"      - {csv_path.name}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Check if Organizations might be named differently\n",
    "print(\"üîç CHECKING FOR ORGANIZATIONS-RELATED FILES:\")\n",
    "all_csv_files = list(DATA_DIR.glob('*.csv')) if DATA_DIR.exists() else []\n",
    "org_related = [f for f in all_csv_files if 'org' in f.name.lower()]\n",
    "if org_related:\n",
    "    print(f\"   Found possibly related files: {[f.name for f in org_related]}\")\n",
    "else:\n",
    "    print(\"   No organization-related CSV files found\")\n",
    "\n",
    "print(f\"\\nüìä SUMMARY:\")\n",
    "print(f\"   Target entities: {len(target_entities)}\")\n",
    "print(f\"   CSV files found: {len([e for e in target_entities if e in csv_analysis])}\")\n",
    "print(f\"   Missing CSV files: {len(target_entities) - len([e for e in target_entities if e in csv_analysis])}\")\n",
    "print(f\"   Total new fields to add: 469\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
